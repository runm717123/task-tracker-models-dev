{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 422,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VGxoT5r_oDv",
        "outputId": "a59662af-ffb0-465c-e684-5e6cd358ce68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 423,
      "metadata": {
        "id": "ZWCwN_S_bh0_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# this is necessary for tensorflowjswizard\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MajeDX0rDZ0p"
      },
      "source": [
        "# Import & Model load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 424,
      "metadata": {
        "id": "sIJuwjgJCT0a"
      },
      "outputs": [],
      "source": [
        "use_model_path = '/content/drive/MyDrive/ndev-task-tracker/universal-sentence-encoder-tensorflow1-lite-v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 425,
      "metadata": {
        "id": "d3c6kMfR-DXU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text  # required for USE Lite\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 426,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RcIej57UViGc",
        "outputId": "318c9782-9973-4e65-95fb-9f37ba5d5642"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.18.0\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 427,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hrsnhhuPuui",
        "outputId": "f42ad6f5-53d3-4520-ced3-294bb7c3c481"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 427,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# 1. Load the Universal Sentence Encoder Lite\n",
        "embed = hub.load(use_model_path)\n",
        "\n",
        "# 2. Load the SentencePiece tokenizer model directly from path\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"{use_model_path}/assets/universal_encoder_8k_spm.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 428,
      "metadata": {
        "id": "vWJ2hnRDD3l-"
      },
      "outputs": [],
      "source": [
        "embed_fn = embed.signatures[\"default\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXs6-avADiJs"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 429,
      "metadata": {
        "id": "5LIS6TavFrT4"
      },
      "outputs": [],
      "source": [
        "# USE Lite is designed to be smaller and mobile/web-friendly, so it does not contain its own tokenizer.\n",
        "# because the embed_fn signature of the Universal Sentence Encoder Lite model you loaded expects the input in this sparse format. If you tried to pass a dense tensor or just a list of token IDs directly, the model would likely throw an error.\n",
        "\n",
        "def to_sparse(sentences):\n",
        "    # Encode sentences to list of token ids\n",
        "    ids = [sp.encode(s) for s in sentences]\n",
        "\n",
        "    # Create values and indices for SparseTensor\n",
        "    values = [token for sent in ids for token in sent]\n",
        "    indices = [[i, j] for i, sent in enumerate(ids) for j in range(len(sent))]\n",
        "    dense_shape = [len(ids), max(len(sent) for sent in ids)]\n",
        "\n",
        "    # Convert to required tensors\n",
        "    return {\n",
        "        \"values\": tf.constant(values, dtype=tf.int64),\n",
        "        \"indices\": tf.constant(indices, dtype=tf.int64),\n",
        "        \"dense_shape\": tf.constant(dense_shape, dtype=tf.int64),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAOMjZRqKDtt"
      },
      "outputs": [],
      "source": [
        "valid_title = [\n",
        "    \"Project Sprint 1\",\n",
        "    \"Project Sprint 5\",\n",
        "    \"Project Sprint 1.1\",\n",
        "    \"Project Sprint 5.1\",\n",
        "    \"TaskHive Dev\",\n",
        "    \"Ndev task tracker\",\n",
        "    \"Spenicle v1\",\n",
        "    \"Zenventory\",\n",
        "    \"FlowNest\"\n",
        "]\n",
        "\n",
        "meetings = [\n",
        "    \"planning sprint\",\n",
        "    \"designing system architecture\",\n",
        "    \"project discussion\",\n",
        "    \"soda\",\n",
        "    \"1:1 with manager\",\n",
        "    \"attending a meeting\",\n",
        "    \"developer catchup\",\n",
        "    \"daily standup\",\n",
        "    \"internal meeting\",\n",
        "    \"english class\",\n",
        "    \"running daily standup\",\n",
        "    \"meeting with mr colleague\",\n",
        "    \"meet with mrs jane\"\n",
        "]\n",
        "\n",
        "background_task = [\n",
        "    \"setting up CI/CD\",\n",
        "    \"configuring docker\",\n",
        "    \"writing API spec\",\n",
        "    \"deploying app\",\n",
        "    \"refactoring code\",\n",
        "    \"writing documentation\",\n",
        "    \"resolving merge conflicts\",\n",
        "    \"pushing to GitHub\",\n",
        "    \"committing changes\",\n",
        "    \"optimizing database\",\n",
        "    \"managing backlog\",\n",
        "]\n",
        "\n",
        "general_tasks = [\n",
        "    \"fixing bugs\",\n",
        "    \"reviewing PRs\",\n",
        "    \"reviewing code\",\n",
        "    \"fixing linter issues\",\n",
        "    \"updating documentation\",\n",
        "    \"pair programming\",\n",
        "    \"resolving bugs\",\n",
        "    \"preparing presentation\",\n",
        "    \"presenting updates\",\n",
        "    \"discussing roadmap\",\n",
        "    \"collaborating on design\",\n",
        "    \"writing proposal\",\n",
        "]\n",
        "\n",
        "general_activities = [\n",
        "    \"watching a movie\",\n",
        "    \"playing games\",\n",
        "    \"eating out\",\n",
        "    \"scrolling TikTok\",\n",
        "    \"cooking dinner\",\n",
        "    \"taking a nap\",\n",
        "    \"chatting with friends\",\n",
        "    \"binge-watching Netflix\",\n",
        "    \"reading a novel\",\n",
        "    \"doing laundry\",\n",
        "    \"shopping online\",\n",
        "    \"going to the mall\",\n",
        "    \"napping\",\n",
        "    \"watching YouTube\",\n",
        "    \"cleaning room\",\n",
        "    \"going for a walk\",\n",
        "    \"checking social media\",\n",
        "    \"ordering food\",\n",
        "    \"scrolling Instagram\",\n",
        "    \"taking a break\",\n",
        "]\n",
        "\n",
        "project_tasks = [\n",
        "    \"writing code\",\n",
        "    \"writing unit tests\",\n",
        "    \"debugging memory leak\",\n",
        "    \"benchmarking app\",\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 431,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQVs5h4E_4o2",
        "outputId": "77f94adb-d13a-41a2-ca69-7cd70afdb8bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You have  67 data points\n"
          ]
        }
      ],
      "source": [
        "# for evaluation\n",
        "class_names = [\n",
        "    \"valid_title\",\n",
        "    \"background_task\",\n",
        "    \"meetings\",\n",
        "    \"general_tasks\",\n",
        "    \"general_activities\",\n",
        "    \"project_tasks\",\n",
        "]\n",
        "\n",
        "# Combine all with labels\n",
        "raw_data = []\n",
        "raw_data += [(item, 0) for item in valid_title]\n",
        "raw_data += [(item, 1) for item in background_task]\n",
        "raw_data += [(item, 2) for item in meetings]\n",
        "raw_data += [(item, 3) for item in general_tasks]\n",
        "raw_data += [(item, 4) for item in general_activities]\n",
        "raw_data += [(item, 5) for item in project_tasks]\n",
        "\n",
        "print('You have ', len(raw_data), 'data points')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCbp3tfEDsH3"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 432,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzTSb0KxA5D4",
        "outputId": "070ce1c9-2024-454c-9005-87eda786efa5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 sentences: ['project sprint 1' 'project sprint 5' 'project sprint 1.1'\n",
            " 'project sprint 5.1' 'reapit dev']\n",
            "First 5 labels: [0 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for sentence, label in raw_data:\n",
        "    sentences.append(sentence.lower())\n",
        "    labels.append(label)\n",
        "\n",
        "sentences = np.array(sentences)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Display the first few elements to verify\n",
        "print(f\"First 5 sentences: {sentences[:5]}\")\n",
        "print(f\"First 5 labels: {labels[:5]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 433,
      "metadata": {
        "id": "bBSB-3KmHrmJ"
      },
      "outputs": [],
      "source": [
        "sparse_input = to_sparse(sentences)\n",
        "embeddings = embed_fn(**sparse_input)['default']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo_2hR-cMxXU"
      },
      "source": [
        "## data splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9VikDolr5W",
        "outputId": "a44453cd-e22d-4299-d5b4-c7fad42d0a72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 7\n"
          ]
        }
      ],
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    embeddings.numpy(), labels, test_size=0.09, stratify=labels, random_state=5\n",
        ")\n",
        "\n",
        "# for now no need test split, because the data is small\n",
        "# Second split: 30% val, 10% test from temp (i.e., 75/25 split of remaining 40%)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(\n",
        "#     X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
        "# )\n",
        "\n",
        "print(len(x_train), len(x_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cfTuLNsOJQa"
      },
      "source": [
        "## prod setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7iyj6jWODi5",
        "outputId": "b0038aea-3a8a-4e47-ba95-8810b7016d3d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "67"
            ]
          },
          "execution_count": 435,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train = np.concatenate((x_train, x_val), axis=0)\n",
        "y_train = np.concatenate((y_train, y_val), axis=0)\n",
        "len(x_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RtrjQS7D4FN"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4-2xXAJ-RBb",
        "outputId": "62a187d0-4865-425b-8e31-728c3fd7862e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 4ms/step - loss: 1.7817 - accuracy: 0.2537\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.7476 - accuracy: 0.3284\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.7239 - accuracy: 0.4627\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6985 - accuracy: 0.4925\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6695 - accuracy: 0.5075\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6533 - accuracy: 0.5224\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6172 - accuracy: 0.5821\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5875 - accuracy: 0.5970\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5545 - accuracy: 0.6269\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.5289 - accuracy: 0.6269\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4967 - accuracy: 0.6418\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4690 - accuracy: 0.7164\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.4297 - accuracy: 0.6716\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3998 - accuracy: 0.7313\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3561 - accuracy: 0.7015\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3429 - accuracy: 0.6866\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2848 - accuracy: 0.7313\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2529 - accuracy: 0.7313\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2186 - accuracy: 0.7164\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2171 - accuracy: 0.6567\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1769 - accuracy: 0.7164\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1666 - accuracy: 0.7463\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.1137 - accuracy: 0.7313\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0919 - accuracy: 0.7910\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0717 - accuracy: 0.7164\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.0468 - accuracy: 0.7015\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0231 - accuracy: 0.7612\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.9755 - accuracy: 0.7612\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.9900 - accuracy: 0.7015\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9508 - accuracy: 0.7313\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.9487 - accuracy: 0.8060\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9295 - accuracy: 0.8060\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.8857 - accuracy: 0.8209\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.8874 - accuracy: 0.8060\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.8715 - accuracy: 0.8209\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8611 - accuracy: 0.8507\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 8ms/step - loss: 0.8405 - accuracy: 0.8209\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.7918 - accuracy: 0.8358\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.8250 - accuracy: 0.8358\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7743 - accuracy: 0.8507\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7592 - accuracy: 0.8657\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7365 - accuracy: 0.8209\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7254 - accuracy: 0.8358\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.7218 - accuracy: 0.8358\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7059 - accuracy: 0.8806\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6879 - accuracy: 0.8657\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6797 - accuracy: 0.8657\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6666 - accuracy: 0.8955\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6683 - accuracy: 0.8657\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.8060\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d8118d12950>"
            ]
          },
          "execution_count": 436,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(512,)),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFmMie__MO6Q"
      },
      "source": [
        "## evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1r0noPUdIkGZ",
        "outputId": "af73e802-35db-4a69-c069-3daab48973ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Val Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(f\"Val Accuracy: {acc:.2%}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va981srmIqZl",
        "outputId": "126637e7-ff6c-4492-de3a-8e2ed87295ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n",
            "[0.2849344  0.52572596 0.43856803]\n",
            "['general_tasks', 'general_activities', 'meetings']\n"
          ]
        }
      ],
      "source": [
        "new_sentences = [\"writing code\", \"eating a little pizza for a minute and wrote a code\", \"catchup with mr x\"]\n",
        "new_input = to_sparse(new_sentences)\n",
        "new_embeddings = embed_fn(**new_input)['default']\n",
        "\n",
        "predictions = model.predict(new_embeddings)\n",
        "# print(predictions) # values near 1 = work, near 0 = not work\n",
        "confidences = predictions.max(axis=1)\n",
        "print(confidences)\n",
        "predicted_labels = predictions.argmax(axis=1)\n",
        "predicted_class_names = [class_names[label] for label in predicted_labels]\n",
        "print(predicted_class_names)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LggwnI-Nyf3R"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 382,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E82qmSaGU4qs",
        "outputId": "0826a287-1a97-423d-9c59-cc64841ba1b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('saved_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
