{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "exzc1Y5KPNPf"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_VGxoT5r_oDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94f8c6a1-1b9a-4de6-ae2d-55a26b2da381"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# this is necessary for tensorflowjswizard\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "ZWCwN_S_bh0_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import & Model load"
      ],
      "metadata": {
        "id": "MajeDX0rDZ0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_model_path = '/content/drive/MyDrive/ndev-task-tracker/universal-sentence-encoder-tensorflow1-lite-v2'"
      ],
      "metadata": {
        "id": "sIJuwjgJCT0a"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "d3c6kMfR-DXU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "RcIej57UViGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c55286a6-c3da-4532-a3b7-3f2e4aa5aa7a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed = hub.load(use_model_path)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"{use_model_path}/assets/universal_encoder_8k_spm.model\")"
      ],
      "metadata": {
        "id": "3hrsnhhuPuui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01c628cd-4e85-41a7-a065-067a55ab059c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_fn = embed.signatures[\"default\"]"
      ],
      "metadata": {
        "id": "vWJ2hnRDD3l-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "XXs6-avADiJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USE Lite is designed to be smaller and mobile/web-friendly, so it does not contain its own tokenizer.\n",
        "# because the embed_fn signature of the Universal Sentence Encoder Lite model you loaded expects the input in this sparse format. If you tried to pass a dense tensor or just a list of token IDs directly, the model would likely throw an error.\n",
        "\n",
        "def to_sparse(sentences):\n",
        "    # Encode sentences to list of token ids\n",
        "    ids = [sp.encode(s) for s in sentences]\n",
        "\n",
        "    # Create values and indices for SparseTensor\n",
        "    values = [token for sent in ids for token in sent]\n",
        "    indices = [[i, j] for i, sent in enumerate(ids) for j in range(len(sent))]\n",
        "    dense_shape = [len(ids), max(len(sent) for sent in ids)]\n",
        "\n",
        "    # Convert to required tensors\n",
        "    return {\n",
        "        \"values\": tf.constant(values, dtype=tf.int64),\n",
        "        \"indices\": tf.constant(indices, dtype=tf.int64),\n",
        "        \"dense_shape\": tf.constant(dense_shape, dtype=tf.int64),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5LIS6TavFrT4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "note: dataset size are not affecting the model size (explicitly)"
      ],
      "metadata": {
        "id": "uJ94nYlv5Ylj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# this is necessary for tensorflowjswizard\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\"\n",
        "\n",
        "valid_title = [\n",
        "    \"project sprint 1\",\n",
        "    \"project sprint 5\",\n",
        "    \"project sprint 1.1\",\n",
        "    \"project sprint 5.1\",\n",
        "    \"taskhive dev\",\n",
        "    \"ndev task tracker\",\n",
        "    \"spenicle v1\",\n",
        "    \"zenventory\",\n",
        "    \"flownest\",\n",
        "    \"contact app\",\n",
        "    \"property web app\",\n",
        "    \"pronews\"\n",
        "]\n",
        "\n",
        "meetings = [\n",
        "    \"project backlog refinement\",\n",
        "    \"planning sprint\",\n",
        "    \"sprint retrospective session\",\n",
        "    \"designing system architecture\",\n",
        "    \"project discussion\",\n",
        "    \"soda\",\n",
        "    \"1:1 with manager\",\n",
        "    \"attending a meeting\",\n",
        "    \"developer catchup\",\n",
        "    \"daily standup\",\n",
        "    \"daily meeting\",\n",
        "    \"internal meeting\",\n",
        "    \"running daily standup\",\n",
        "    \"meeting with mr colleague\",\n",
        "    \"meet with mrs jane\",\n",
        "    \"daily scrum meeting\",\n",
        "    \"brainstorming session\",\n",
        "    \"weekly sync up\",\n",
        "    \"team meeting\",\n",
        "    \"client call\",\n",
        "    \"quarterly review\",\n",
        "    \"stand-up meeting\",\n",
        "    \"sync meeting\",\n",
        "    \"discussion with the team\",\n",
        "    \"meeting with stakeholders\",\n",
        "    \"project review meeting\",\n",
        "    \"technical discussion\",\n",
        "    \"design review meeting\",\n",
        "    \"planning meeting for next quarter\",\n",
        "    \"client demo session\",\n",
        "    \"internal team sync\",\n",
        "    \"meeting with product manager\",\n",
        "    \"daily huddle\",\n",
        "    \"weekly planning session\"\n",
        "]\n",
        "\n",
        "background_task = [\n",
        "    \"setting up ci/cd\",\n",
        "    \"configuring docker\",\n",
        "    \"writing api spec\",\n",
        "    \"deploying app\",\n",
        "    \"refactoring code\",\n",
        "    \"writing documentation\",\n",
        "    \"resolving merge conflicts\",\n",
        "    \"committing changes\",\n",
        "    \"optimizing database\",\n",
        "    \"managing backlog\",\n",
        "    \"setting up continuous integration and deployment pipelines\",\n",
        "    \"docker container configuration\",\n",
        "    \"api contract documentation\",\n",
        "    \"application deployment to production\",\n",
        "    \"codebase refactoring\",\n",
        "    \"technical documentation creation\",\n",
        "    \"resolving git merge conflicts\",\n",
        "    \"pushing code to remote repository\",\n",
        "    \"committing code changes\",\n",
        "    \"database performance optimization\",\n",
        "    \"project backlog grooming\",\n",
        "    \"configuring build automation\",\n",
        "    \"writing user guides\",\n",
        "    \"resolving version control conflicts\",\n",
        "    \"deploying a new service\",\n",
        "    \"improving database query performance\"\n",
        "]\n",
        "\n",
        "general_tasks = [\n",
        "    \"fixing bugs\",\n",
        "    \"reviewing prs\",\n",
        "    \"reviewing code\",\n",
        "    \"fixing linter issues\",\n",
        "    \"updating documentation\",\n",
        "    \"pair programming\",\n",
        "    \"resolving bugs\",\n",
        "    \"preparing presentation\",\n",
        "    \"presenting updates\",\n",
        "    \"discussing roadmap\",\n",
        "    \"collaborating on design\",\n",
        "    \"writing proposal\",\n",
        "    \"self explore\",\n",
        "    \"self research\",\n",
        "    \"research and found issue with memory optimization in react components\",\n",
        "    \"bug research\",\n",
        "    \"debugging application errors\",\n",
        "    \"conducting code reviews\",\n",
        "    \"addressing static analysis warnings\",\n",
        "    \"updating technical specifications\",\n",
        "    \"collaborative coding session\",\n",
        "    \"troubleshooting and resolving software defects\",\n",
        "    \"creating slides for presentation\",\n",
        "    \"providing project updates\",\n",
        "    \"discussing project roadmap\",\n",
        "    \"collaborating on system design\",\n",
        "    \"writing a technical proposal\",\n",
        "    \"exploring new technologies for a project\",\n",
        "    \"conducting technical research\",\n",
        "    \"investigating memory issues in frontend components\",\n",
        "    \"researching software bugs\"\n",
        "]\n",
        "\n",
        "general_activities = [\n",
        "    \"afternoon prayer\",\n",
        "    \"watching a movie\",\n",
        "    \"playing games\",\n",
        "    \"eating out\",\n",
        "    \"scrolling tiktok\",\n",
        "    \"cooking dinner\",\n",
        "    \"taking a nap\",\n",
        "    \"chatting with friends\",\n",
        "    \"binge-watching netflix\",\n",
        "    \"reading a novel\",\n",
        "    \"doing laundry\",\n",
        "    \"shopping online\",\n",
        "    \"going to the mall\",\n",
        "    \"napping\",\n",
        "    \"watching youtube\",\n",
        "    \"cleaning room\",\n",
        "    \"going for a walk\",\n",
        "    \"checking social media\",\n",
        "    \"ordering food\",\n",
        "    \"scrolling instagram\",\n",
        "    \"taking a break\",\n",
        "    \"technical training\",\n",
        "    \"english class\",\n",
        "    \"compliance training session\",\n",
        "    \"web development security training\",\n",
        "    \"training assesment\",\n",
        "    \"prayer time in the afternoon\",\n",
        "    \"watching a film for leisure\",\n",
        "    \"playing video games for relaxation\",\n",
        "    \"dining at a restaurant\",\n",
        "    \"browsing short videos on tiktok\",\n",
        "    \"preparing a meal for dinner\",\n",
        "    \"taking a short rest\",\n",
        "    \"talking with colleagues informally\",\n",
        "    \"watching multiple episodes on netflix\",\n",
        "    \"reading a fiction book\",\n",
        "    \"doing the weekly laundry\",\n",
        "    \"purchasing items online\",\n",
        "    \"visiting a shopping mall\",\n",
        "    \"getting some sleep\",\n",
        "    \"watching videos on youtube for entertainment\",\n",
        "    \"tidying up the living space\",\n",
        "    \"going for a short walk outside\",\n",
        "    \"checking updates on social media platforms\",\n",
        "    \"ordering food for delivery\",\n",
        "    \"browsing photos and videos on instagram\",\n",
        "    \"taking a short pause from work\",\n",
        "    \"attending a technical skill building session\",\n",
        "    \"participating in an English language course\",\n",
        "    \"completing mandatory compliance training\",\n",
        "    \"attending a web security workshop\",\n",
        "    \"undergoing a training evaluation\"\n",
        "]\n",
        "\n",
        "# can be useful when no valid_title detected\n",
        "project_tasks = [\n",
        "    \"working on a new ui design\",\n",
        "    \"create new component for new page\",\n",
        "    \"resolve feedback: update the formatData approach\",\n",
        "    \"resolve feedback from mr. xxx\",\n",
        "    \"working on a new feature\",\n",
        "    \"working on the new drawer\",\n",
        "    \"adjust the page gdpr message\",\n",
        "    \"handle form submit behaviour\",\n",
        "    \"writing unit tests\",\n",
        "    \"debugging memory leak\",\n",
        "    \"benchmarking app\",\n",
        "    \"designing a new user interface for the application\",\n",
        "    \"developing a reusable component for a new page\",\n",
        "    \"addressing feedback on the data formatting logic\",\n",
        "    \"implementing changes based on feedback from a team member\",\n",
        "    \"building a new feature based on requirements\",\n",
        "    \"working on the implementation of a new navigation drawer\",\n",
        "    \"modifying the gdpr consent message displayed on the page\",\n",
        "    \"implementing the logic for form submission and validation\",\n",
        "    \"writing comprehensive unit tests for a module\",\n",
        "    \"investigating and fixing a memory leak issue\",\n",
        "    \"conducting performance benchmarking for the application\"\n",
        "]\n",
        "\n",
        "dataset_dict = {\n",
        "    \"valid_title\": valid_title,\n",
        "    \"background_task\": background_task,\n",
        "    \"meetings\": meetings,\n",
        "    \"general_tasks\": general_tasks,\n",
        "    \"general_activities\": general_activities,\n",
        "    \"project_tasks\": project_tasks,\n",
        "}"
      ],
      "metadata": {
        "id": "GAOMjZRqKDtt"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Back-translation\n",
        "\n",
        "english -> france -> english\n",
        "\n",
        "warning: this section can take long time\n",
        "\n",
        "this is not required to run, as the original dataset is quite sufficient"
      ],
      "metadata": {
        "id": "exzc1Y5KPNPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "# Load models for English → French and French → English\n",
        "en_to_fr_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "en_to_fr_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-en-fr\")\n",
        "\n",
        "fr_to_en_tokenizer = MarianTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n",
        "fr_to_en_model = MarianMTModel.from_pretrained(\"Helsinki-NLP/opus-mt-fr-en\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVtr9mqiO6BJ",
        "outputId": "68089d49-120e-4fcf-a9da-21ae7263d26b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text, tokenizer, model):\n",
        "    inputs = tokenizer.encode(text, return_tensors=\"pt\")\n",
        "    outputs = model.generate(inputs, max_length=64, num_beams=4, early_stopping=True)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "def back_translate(text):\n",
        "    \"\"\"\n",
        "    Performs back-translation from English to French and then back to English.\n",
        "\n",
        "    Returns:\n",
        "        str: The back-translated English text.\n",
        "    \"\"\"\n",
        "    fr_text = translate(text, en_to_fr_tokenizer, en_to_fr_model)\n",
        "    back_to_en = translate(fr_text, fr_to_en_tokenizer, fr_to_en_model)\n",
        "    return back_to_en"
      ],
      "metadata": {
        "id": "DpFtTtSJSTQg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "457e0075-4d2b-47b3-85a2-19f7993cfc79",
        "outputId": "b368bbf9-024f-4e68-cbbf-0f9e6f0c6236"
      },
      "source": [
        "background_task_bt = []\n",
        "meetings_bt = []\n",
        "general_tasks_bt = []\n",
        "general_activities_bt = []\n",
        "project_tasks_bt = []\n",
        "\n",
        "# Back-translate sentences for each category (excluding valid_title)\n",
        "for sentence in background_task:\n",
        "    background_task_bt.append(back_translate(sentence))\n",
        "\n",
        "for sentence in meetings:\n",
        "    meetings_bt.append(back_translate(sentence))\n",
        "\n",
        "for sentence in general_tasks:\n",
        "    general_tasks_bt.append(back_translate(sentence))\n",
        "\n",
        "for sentence in general_activities:\n",
        "    general_activities_bt.append(back_translate(sentence))\n",
        "\n",
        "for sentence in project_tasks:\n",
        "    project_tasks_bt.append(back_translate(sentence))\n",
        "\n",
        "\n",
        "print(\"Back-translated background_tasks:\", background_task_bt[:5])\n",
        "print(\"Back-translated meetings:\", meetings_bt[:5])\n",
        "print(\"Back-translated general_tasks:\", general_tasks_bt[:5])\n",
        "print(\"Back-translated general_activities:\", general_activities_bt[:5])\n",
        "print(\"Back-translated project_tasks:\", project_tasks_bt[:5])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-42-3917011047.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Back-translate sentences for each category (excluding valid_title)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackground_task\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mbackground_task_bt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mback_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmeetings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-41-590552432.py\u001b[0m in \u001b[0;36mback_translate\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mfr_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_to_fr_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_to_fr_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mback_to_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_to_en_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfr_to_en_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mback_to_en\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-41-590552432.py\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(text, tokenizer, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_beams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly_stopping\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[0m\n\u001b[1;32m   2642\u001b[0m             )\n\u001b[1;32m   2643\u001b[0m             \u001b[0;31m# 12. run beam sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2644\u001b[0;31m             result = self._beam_search(\n\u001b[0m\u001b[1;32m   2645\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_beam_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   4077\u001b[0m             \u001b[0mmodel_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"output_hidden_states\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_hidden_states\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4079\u001b[0;31m             \u001b[0mmodel_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4081\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1546\u001b[0m                 )\n\u001b[1;32m   1547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1548\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m   1549\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, past_key_value, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1301\u001b[0;31m         decoder_outputs = self.decoder(\n\u001b[0m\u001b[1;32m   1302\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, head_mask, cross_attn_head_mask, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1080\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m             layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m   1083\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m                 \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/marian/modeling_marian.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, layer_head_mask, cross_attn_layer_head_mask, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresidual\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder_attn_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Fully Connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         return F.layer_norm(\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2908\u001b[0m             \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2909\u001b[0m         )\n\u001b[0;32m-> 2910\u001b[0;31m     return torch.layer_norm(\n\u001b[0m\u001b[1;32m   2911\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2912\u001b[0m     )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Create a dictionary to store the back-translated data\n",
        "back_translated_data_dict = {\n",
        "    \"background_task_bt\": background_task_bt,\n",
        "    \"meetings_bt\": meetings_bt,\n",
        "    \"general_tasks_bt\": general_tasks_bt,\n",
        "    \"general_activities_bt\": general_activities_bt,\n",
        "    \"project_tasks_bt\": project_tasks_bt\n",
        "}\n",
        "\n",
        "# Define the filename for the pickle file\n",
        "pickle_filename = \"back_translated_data.pkl\"\n",
        "\n",
        "# Save the dictionary to a pickle file\n",
        "with open(pickle_filename, 'wb') as f:\n",
        "    pickle.dump(back_translated_data_dict, f)\n",
        "\n",
        "print(f\"Back-translated data saved to {pickle_filename}\")"
      ],
      "metadata": {
        "id": "iwi2GJmXVOQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "KCbp3tfEDsH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation\n",
        "class_names = [\n",
        "    \"valid_title\",\n",
        "    \"background_task\",\n",
        "    \"meetings\",\n",
        "    \"general_tasks\",\n",
        "    \"general_activities\",\n",
        "    \"project_tasks\",\n",
        "]\n",
        "\n",
        "# Combine all with labels\n",
        "raw_data = []\n",
        "raw_data += [(item, 0) for item in valid_title]\n",
        "raw_data += [(item, 1) for item in background_task]\n",
        "raw_data += [(item, 2) for item in meetings]\n",
        "raw_data += [(item, 3) for item in general_tasks]\n",
        "raw_data += [(item, 4) for item in general_activities]\n",
        "raw_data += [(item, 5) for item in project_tasks]\n",
        "\n",
        "print('You have ', len(raw_data), 'data points')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQVs5h4E_4o2",
        "outputId": "16ed3883-a31e-4456-c117-c027f234a176"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have  177 data points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for sentence, label in raw_data:\n",
        "    sentences.append(sentence.lower())\n",
        "    labels.append(label)\n",
        "\n",
        "sentences = np.array(sentences)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Display the first few elements to verify\n",
        "print(f\"First 5 sentences: {sentences[:5]}\")\n",
        "print(f\"First 5 labels: {labels[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzTSb0KxA5D4",
        "outputId": "f3c913ed-3b98-4acb-9382-6af5bee2017c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 sentences: ['project sprint 1' 'project sprint 5' 'project sprint 1.1'\n",
            " 'project sprint 5.1' 'taskhive dev']\n",
            "First 5 labels: [0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_input = to_sparse(sentences)\n",
        "embeddings = embed_fn(**sparse_input)['default']"
      ],
      "metadata": {
        "id": "bBSB-3KmHrmJ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data splitting"
      ],
      "metadata": {
        "id": "Xo_2hR-cMxXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    embeddings.numpy(), labels, test_size=0.15, stratify=labels, random_state=5\n",
        ")\n",
        "\n",
        "print(len(x_train), len(x_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9VikDolr5W",
        "outputId": "e8924293-69db-4112-c053-ba7f9a84d42a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Check if y_val have proper distribution\n",
        "y_val_counts = collections.Counter(y_val)\n",
        "\n",
        "# Print the counts for each class\n",
        "print(\"Distribution of classes in y_val:\")\n",
        "for label, count in y_val_counts.items():\n",
        "    print(f\"Class {class_names[label]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpEcKwnsssYf",
        "outputId": "dd67ce17-2f9f-40c1-a477-60c4c8756cd9"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution of classes in y_val:\n",
            "Class general_activities: 8\n",
            "Class meetings: 5\n",
            "Class project_tasks: 3\n",
            "Class general_tasks: 5\n",
            "Class background_task: 4\n",
            "Class valid_title: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prod setup"
      ],
      "metadata": {
        "id": "3cfTuLNsOJQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# combine all dataset for final result\n",
        "\n",
        "x_train = np.concatenate((x_train, x_val), axis=0)\n",
        "y_train = np.concatenate((y_train, y_val), axis=0)\n",
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7iyj6jWODi5",
        "outputId": "69427693-c9b6-42ff-d382-41da9c1b1765"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "177"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "1RtrjQS7D4FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(512,)),\n",
        "    tf.keras.layers.Dense(55, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50)"
      ],
      "metadata": {
        "id": "p4-2xXAJ-RBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6647ae-1b90-4441-bb7e-c3d26757c362",
        "collapsed": true
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6/6 [==============================] - 2s 17ms/step - loss: 1.7670 - accuracy: 0.2881\n",
            "Epoch 2/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.6943 - accuracy: 0.5311\n",
            "Epoch 3/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6296 - accuracy: 0.5480\n",
            "Epoch 4/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.5531 - accuracy: 0.5876\n",
            "Epoch 5/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.4754 - accuracy: 0.6158\n",
            "Epoch 6/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.4077 - accuracy: 0.5819\n",
            "Epoch 7/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 1.3267 - accuracy: 0.5876\n",
            "Epoch 8/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2604 - accuracy: 0.6497\n",
            "Epoch 9/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1903 - accuracy: 0.6271\n",
            "Epoch 10/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1469 - accuracy: 0.6102\n",
            "Epoch 11/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.0796 - accuracy: 0.7175\n",
            "Epoch 12/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.0294 - accuracy: 0.7006\n",
            "Epoch 13/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.9760 - accuracy: 0.7401\n",
            "Epoch 14/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.9515 - accuracy: 0.7401\n",
            "Epoch 15/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.9036 - accuracy: 0.7797\n",
            "Epoch 16/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.8846 - accuracy: 0.7740\n",
            "Epoch 17/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.8316 - accuracy: 0.8023\n",
            "Epoch 18/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8009 - accuracy: 0.8362\n",
            "Epoch 19/50\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.7589 - accuracy: 0.8249\n",
            "Epoch 20/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7280 - accuracy: 0.8644\n",
            "Epoch 21/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.7040 - accuracy: 0.8249\n",
            "Epoch 22/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.6729 - accuracy: 0.8531\n",
            "Epoch 23/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6589 - accuracy: 0.8531\n",
            "Epoch 24/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.6144 - accuracy: 0.8588\n",
            "Epoch 25/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5907 - accuracy: 0.8644\n",
            "Epoch 26/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5617 - accuracy: 0.9096\n",
            "Epoch 27/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.5535 - accuracy: 0.8757\n",
            "Epoch 28/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5216 - accuracy: 0.8870\n",
            "Epoch 29/50\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5148 - accuracy: 0.8814\n",
            "Epoch 30/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4744 - accuracy: 0.9040\n",
            "Epoch 31/50\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.4771 - accuracy: 0.9096\n",
            "Epoch 32/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4450 - accuracy: 0.9209\n",
            "Epoch 33/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.4405 - accuracy: 0.9266\n",
            "Epoch 34/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4274 - accuracy: 0.9209\n",
            "Epoch 35/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.9153\n",
            "Epoch 36/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3899 - accuracy: 0.9266\n",
            "Epoch 37/50\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3428 - accuracy: 0.9492\n",
            "Epoch 38/50\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3662 - accuracy: 0.9492\n",
            "Epoch 39/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3695 - accuracy: 0.9379\n",
            "Epoch 40/50\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.3373 - accuracy: 0.9435\n",
            "Epoch 41/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3156 - accuracy: 0.9605\n",
            "Epoch 42/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3205 - accuracy: 0.9548\n",
            "Epoch 43/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3083 - accuracy: 0.9661\n",
            "Epoch 44/50\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2994 - accuracy: 0.9718\n",
            "Epoch 45/50\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.2959 - accuracy: 0.9548\n",
            "Epoch 46/50\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2702 - accuracy: 0.9774\n",
            "Epoch 47/50\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.9379\n",
            "Epoch 48/50\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2674 - accuracy: 0.9605\n",
            "Epoch 49/50\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2757 - accuracy: 0.9548\n",
            "Epoch 50/50\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2608 - accuracy: 0.9718\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7ed65a6eb6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "nFmMie__MO6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(f\"Val Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "id": "1r0noPUdIkGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50d17399-90d6-42ae-d478-7a14dee5ea53"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7ed65a6f4e00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentences = [\"my app v1\", \"writing code\", \"eating a little pizza for a minute and wrote a code\", \"catchup with mr x\", \"Quarterly system architecture review meeting\"]\n",
        "new_input = to_sparse(new_sentences)\n",
        "new_embeddings = embed_fn(**new_input)['default']\n",
        "\n",
        "predictions = model.predict(new_embeddings)\n",
        "confidences = predictions.max(axis=1)\n",
        "print(confidences)\n",
        "predicted_labels = predictions.argmax(axis=1)\n",
        "predicted_class_names = [class_names[label] for label in predicted_labels]\n",
        "print(predicted_class_names)\n"
      ],
      "metadata": {
        "id": "Va981srmIqZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4086db28-c32b-451c-f776-543b0059874e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 174ms/step\n",
            "[0.60401493 0.53558314 0.8731531  0.7066516  0.79187334]\n",
            "['valid_title', 'general_tasks', 'general_activities', 'meetings', 'meetings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "LggwnI-Nyf3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model.h5')"
      ],
      "metadata": {
        "id": "E82qmSaGU4qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1c3cec-d164-4218-aaad-eaae00f5f070"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}