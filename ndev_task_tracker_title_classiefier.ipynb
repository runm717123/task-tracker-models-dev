{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_VGxoT5r_oDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43d6d59-d47e-4ec7-913a-4d088aa6890b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# this is necessary for tensorflowjswizard\n",
        "os.environ[\"TF_USE_LEGACY_KERAS\"] = \"1\""
      ],
      "metadata": {
        "id": "ZWCwN_S_bh0_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import & Model load"
      ],
      "metadata": {
        "id": "MajeDX0rDZ0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "use_model_path = '/content/drive/MyDrive/ndev-task-tracker/universal-sentence-encoder-tensorflow1-lite-v2'"
      ],
      "metadata": {
        "id": "sIJuwjgJCT0a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d3c6kMfR-DXU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import sentencepiece as spm\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "id": "RcIej57UViGc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "156a7113-748f-4abd-a8b8-031b852015d6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Load the Universal Sentence Encoder Lite\n",
        "embed = hub.load(use_model_path)\n",
        "\n",
        "# 2. Load the SentencePiece tokenizer model directly from path\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(f\"{use_model_path}/assets/universal_encoder_8k_spm.model\")"
      ],
      "metadata": {
        "id": "3hrsnhhuPuui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c21703c-c123-410b-fa37-1b88445e3523"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en:0' shape=(8002, 256) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_0:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_1:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_2:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_3:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en:0' shape=(8002, 256) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_0:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_1:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_2:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_3:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en:0' shape=(8002, 256) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_0:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_1:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_2:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_3:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Embeddings_en:0' shape=(8002, 256) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_0:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_1:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_2:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n",
            "WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'Encoder_en/KonaTransformer/Encode/Layer_0/TransformerLayer/layer_prepostprocess/layer_norm/layer_norm_scale/part_3:0' shape=(16,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embed_fn = embed.signatures[\"default\"]"
      ],
      "metadata": {
        "id": "vWJ2hnRDD3l-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "XXs6-avADiJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# USE Lite is designed to be smaller and mobile/web-friendly, so it does not contain its own tokenizer.\n",
        "# because the embed_fn signature of the Universal Sentence Encoder Lite model you loaded expects the input in this sparse format. If you tried to pass a dense tensor or just a list of token IDs directly, the model would likely throw an error.\n",
        "\n",
        "def to_sparse(sentences):\n",
        "    # Encode sentences to list of token ids\n",
        "    ids = [sp.encode(s) for s in sentences]\n",
        "\n",
        "    # Create values and indices for SparseTensor\n",
        "    values = [token for sent in ids for token in sent]\n",
        "    indices = [[i, j] for i, sent in enumerate(ids) for j in range(len(sent))]\n",
        "    dense_shape = [len(ids), max(len(sent) for sent in ids)]\n",
        "\n",
        "    # Convert to required tensors\n",
        "    return {\n",
        "        \"values\": tf.constant(values, dtype=tf.int64),\n",
        "        \"indices\": tf.constant(indices, dtype=tf.int64),\n",
        "        \"dense_shape\": tf.constant(dense_shape, dtype=tf.int64),\n",
        "    }\n"
      ],
      "metadata": {
        "id": "5LIS6TavFrT4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_title = [\n",
        "   \"Project Sprint 1\",\n",
        "    \"Project Sprint 5\",\n",
        "    \"Project Sprint 1.1\",\n",
        "    \"Project Sprint 5.1\",\n",
        "    \"TaskHive Dev\",\n",
        "    \"Ndev task tracker\",\n",
        "    \"Spenicle v1\",\n",
        "    \"Zenventory\",\n",
        "    \"FlowNest\"\n",
        "]\n",
        "\n",
        "meetings = [\n",
        "    \"planning sprint\",\n",
        "    \"designing system architecture\",\n",
        "    \"project discussion\",\n",
        "    \"soda\",\n",
        "    \"1:1 with manager\",\n",
        "    \"attending a meeting\",\n",
        "    \"developer catchup\",\n",
        "    \"daily standup\",\n",
        "    \"internal meeting\",\n",
        "    \"english class\",\n",
        "    \"running daily standup\",\n",
        "    \"meeting with mr colleague\",\n",
        "    \"meet with mrs jane\"\n",
        "]\n",
        "\n",
        "background_task = [\n",
        "    \"setting up CI/CD\",\n",
        "    \"configuring docker\",\n",
        "    \"writing API spec\",\n",
        "    \"deploying app\",\n",
        "    \"refactoring code\",\n",
        "    \"writing documentation\",\n",
        "    \"resolving merge conflicts\",\n",
        "    \"pushing to GitHub\",\n",
        "    \"committing changes\",\n",
        "    \"optimizing database\",\n",
        "    \"managing backlog\",\n",
        "]\n",
        "\n",
        "general_tasks = [\n",
        "    \"fixing bugs\",\n",
        "    \"reviewing PRs\",\n",
        "    \"reviewing code\",\n",
        "    \"fixing linter issues\",\n",
        "    \"updating documentation\",\n",
        "    \"pair programming\",\n",
        "    \"resolving bugs\",\n",
        "    \"preparing presentation\",\n",
        "    \"presenting updates\",\n",
        "    \"discussing roadmap\",\n",
        "    \"collaborating on design\",\n",
        "    \"writing proposal\",\n",
        "]\n",
        "\n",
        "general_activities = [\n",
        "    \"watching a movie\",\n",
        "    \"playing games\",\n",
        "    \"eating out\",\n",
        "    \"scrolling TikTok\",\n",
        "    \"cooking dinner\",\n",
        "    \"taking a nap\",\n",
        "    \"chatting with friends\",\n",
        "    \"binge-watching Netflix\",\n",
        "    \"reading a novel\",\n",
        "    \"doing laundry\",\n",
        "    \"shopping online\",\n",
        "    \"going to the mall\",\n",
        "    \"napping\",\n",
        "    \"watching YouTube\",\n",
        "    \"cleaning room\",\n",
        "    \"going for a walk\",\n",
        "    \"checking social media\",\n",
        "    \"ordering food\",\n",
        "    \"scrolling Instagram\",\n",
        "    \"taking a break\",\n",
        "]\n",
        "\n",
        "project_tasks = [\n",
        "    \"writing code\",\n",
        "    \"writing unit tests\",\n",
        "    \"debugging memory leak\",\n",
        "    \"benchmarking app\",\n",
        "]\n"
      ],
      "metadata": {
        "id": "GAOMjZRqKDtt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for evaluation\n",
        "class_names = [\n",
        "    \"valid_title\",\n",
        "    \"background_task\",\n",
        "    \"meetings\",\n",
        "    \"general_tasks\",\n",
        "    \"general_activities\",\n",
        "    \"project_tasks\",\n",
        "]\n",
        "\n",
        "# Combine all with labels\n",
        "raw_data = []\n",
        "raw_data += [(item, 0) for item in valid_title]\n",
        "raw_data += [(item, 1) for item in background_task]\n",
        "raw_data += [(item, 2) for item in meetings]\n",
        "raw_data += [(item, 3) for item in general_tasks]\n",
        "raw_data += [(item, 4) for item in general_activities]\n",
        "raw_data += [(item, 5) for item in project_tasks]\n",
        "\n",
        "print('You have ', len(raw_data), 'data points')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQVs5h4E_4o2",
        "outputId": "54d9a958-21ad-41b0-c324-a38c73b92064"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have  69 data points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## preprocessing"
      ],
      "metadata": {
        "id": "KCbp3tfEDsH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "for sentence, label in raw_data:\n",
        "    sentences.append(sentence.lower())\n",
        "    labels.append(label)\n",
        "\n",
        "sentences = np.array(sentences)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Display the first few elements to verify\n",
        "print(f\"First 5 sentences: {sentences[:5]}\")\n",
        "print(f\"First 5 labels: {labels[:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzTSb0KxA5D4",
        "outputId": "3760ae7d-4652-45c1-9061-25fc962ccff0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 sentences: ['project sprint 1' 'project sprint 5' 'project sprint 1.1'\n",
            " 'project sprint 5.1' 'taskhive dev']\n",
            "First 5 labels: [0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_input = to_sparse(sentences)\n",
        "embeddings = embed_fn(**sparse_input)['default']"
      ],
      "metadata": {
        "id": "bBSB-3KmHrmJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data splitting"
      ],
      "metadata": {
        "id": "Xo_2hR-cMxXU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First split: 70% train, 30% val\n",
        "x_train, x_val, y_train, y_val = train_test_split(\n",
        "    embeddings.numpy(), labels, test_size=0.09, stratify=labels, random_state=5\n",
        ")\n",
        "\n",
        "# for now no need test split, because the data is small\n",
        "# Second split: 30% val, 10% test from temp (i.e., 75/25 split of remaining 40%)\n",
        "# X_val, X_test, y_val, y_test = train_test_split(\n",
        "#     X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42\n",
        "# )\n",
        "\n",
        "print(len(x_train), len(x_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Y9VikDolr5W",
        "outputId": "6a5040f4-1018-43bc-dc25-8e28ec65f9c7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "62 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## prod setup"
      ],
      "metadata": {
        "id": "3cfTuLNsOJQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = np.concatenate((x_train, x_val), axis=0)\n",
        "y_train = np.concatenate((y_train, y_val), axis=0)\n",
        "len(x_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7iyj6jWODi5",
        "outputId": "c7f9a712-0ae6-4299-fb44-9730eb8bad6a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "69"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "1RtrjQS7D4FN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(512,)),\n",
        "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(6, activation=\"softmax\"),\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, epochs=50)"
      ],
      "metadata": {
        "id": "p4-2xXAJ-RBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8177e9b-dfc6-4aeb-f1b6-b3e091aebb9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3/3 [==============================] - 1s 6ms/step - loss: 1.7908 - accuracy: 0.2029\n",
            "Epoch 2/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.7497 - accuracy: 0.3768\n",
            "Epoch 3/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.7122 - accuracy: 0.4348\n",
            "Epoch 4/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6781 - accuracy: 0.4928\n",
            "Epoch 5/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6481 - accuracy: 0.4638\n",
            "Epoch 6/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.6129 - accuracy: 0.4493\n",
            "Epoch 7/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5872 - accuracy: 0.4783\n",
            "Epoch 8/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5699 - accuracy: 0.5797\n",
            "Epoch 9/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.5293 - accuracy: 0.5362\n",
            "Epoch 10/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4972 - accuracy: 0.6377\n",
            "Epoch 11/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.4682 - accuracy: 0.5942\n",
            "Epoch 12/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.4541 - accuracy: 0.5942\n",
            "Epoch 13/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.3879 - accuracy: 0.5797\n",
            "Epoch 14/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3741 - accuracy: 0.6087\n",
            "Epoch 15/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3325 - accuracy: 0.6087\n",
            "Epoch 16/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.3097 - accuracy: 0.5797\n",
            "Epoch 17/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2812 - accuracy: 0.5942\n",
            "Epoch 18/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 1.2407 - accuracy: 0.6812\n",
            "Epoch 19/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2258 - accuracy: 0.7101\n",
            "Epoch 20/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.2058 - accuracy: 0.6522\n",
            "Epoch 21/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1421 - accuracy: 0.7246\n",
            "Epoch 22/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1500 - accuracy: 0.7246\n",
            "Epoch 23/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.1161 - accuracy: 0.7826\n",
            "Epoch 24/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0799 - accuracy: 0.7826\n",
            "Epoch 25/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0863 - accuracy: 0.7681\n",
            "Epoch 26/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 1.0246 - accuracy: 0.8261\n",
            "Epoch 27/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9984 - accuracy: 0.8406\n",
            "Epoch 28/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.9815 - accuracy: 0.8261\n",
            "Epoch 29/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9924 - accuracy: 0.8116\n",
            "Epoch 30/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9622 - accuracy: 0.8696\n",
            "Epoch 31/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.9065 - accuracy: 0.8261\n",
            "Epoch 32/50\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.9049 - accuracy: 0.8986\n",
            "Epoch 33/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.8872 - accuracy: 0.8841\n",
            "Epoch 34/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.8678 - accuracy: 0.8116\n",
            "Epoch 35/50\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.8561 - accuracy: 0.8261\n",
            "Epoch 36/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7939 - accuracy: 0.8696\n",
            "Epoch 37/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7779 - accuracy: 0.8986\n",
            "Epoch 38/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.8841\n",
            "Epoch 39/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.7827 - accuracy: 0.8551\n",
            "Epoch 40/50\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.7616 - accuracy: 0.8841\n",
            "Epoch 41/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.8841\n",
            "Epoch 42/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6832 - accuracy: 0.8551\n",
            "Epoch 43/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6992 - accuracy: 0.8696\n",
            "Epoch 44/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6921 - accuracy: 0.8841\n",
            "Epoch 45/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.8406\n",
            "Epoch 46/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.8551\n",
            "Epoch 47/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.8551\n",
            "Epoch 48/50\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.6012 - accuracy: 0.8551\n",
            "Epoch 49/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.8841\n",
            "Epoch 50/50\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.5611 - accuracy: 0.8841\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x78c477989e50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "nFmMie__MO6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate\n",
        "loss, acc = model.evaluate(x_val, y_val, verbose=0)\n",
        "print(f\"Val Accuracy: {acc:.2%}\")\n"
      ],
      "metadata": {
        "id": "1r0noPUdIkGZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d6e7d0-00e2-4ade-ed3b-77d904bda7a3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Val Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_sentences = [\"writing code\", \"eating a little pizza for a minute and wrote a code\", \"catchup with mr x\"]\n",
        "new_input = to_sparse(new_sentences)\n",
        "new_embeddings = embed_fn(**new_input)['default']\n",
        "\n",
        "predictions = model.predict(new_embeddings)\n",
        "confidences = predictions.max(axis=1)\n",
        "print(confidences)\n",
        "predicted_labels = predictions.argmax(axis=1)\n",
        "predicted_class_names = [class_names[label] for label in predicted_labels]\n",
        "print(predicted_class_names)\n"
      ],
      "metadata": {
        "id": "Va981srmIqZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26ceed9-3cf9-4e48-b321-e1782901e4f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 73ms/step\n",
            "[0.31937888 0.5428822  0.39629632]\n",
            "['general_tasks', 'general_activities', 'meetings']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "LggwnI-Nyf3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('saved_model.h5')"
      ],
      "metadata": {
        "id": "E82qmSaGU4qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0826a287-1a97-423d-9c59-cc64841ba1b5"
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tf_keras/src/engine/training.py:3098: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}